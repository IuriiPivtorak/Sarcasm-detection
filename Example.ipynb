{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "7nA-R1jZomQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f525eafb-1b34-47b2-97a4-b949d770df73"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GhQeguOMph0a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load pre-trained tokenizer and model\n",
        "\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tok = pickle.load(handle)\n",
        "\n",
        "model = load_model('GRU_3layers_full.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPIwPx3Lpshf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model accepts list of strings as an argument\n",
        "# if using it for single document classification still use list i.e ['your text']\n",
        "\n",
        "texts = ['iirc it is true', 'I agree with your point', 'o really, and here I thought you were smart, duh',\n",
        "         'good thing they were totally incompetent, right?', 'how dare you think for yourself!']\n",
        "\n",
        "test_sequences = tok.texts_to_sequences(texts)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=500) # don't change maxlen parameter, model was trained on sequences of length 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hGlvYBRGp6K2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6ca2e458-ca42-4d8c-a780-0ffdea275af4"
      },
      "cell_type": "code",
      "source": [
        "# basic output is list of probabilites of texts being sarcastic\n",
        "\n",
        "model.predict(test_sequences_matrix)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04465069],\n",
              "       [0.14092858],\n",
              "       [0.9507313 ],\n",
              "       [0.9781009 ],\n",
              "       [0.8932558 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "o9R-2s6NsJBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6611e8c4-d10c-4f61-abb3-89703fa8e123"
      },
      "cell_type": "code",
      "source": [
        "# you can output binary values where True means that text was sarcastic if probability if above baseline\n",
        "# here baseline is 50 %.\n",
        "\n",
        "baseline = 0.5\n",
        "predictions = model.predict(test_sequences_matrix) > baseline\n",
        "print(predictions)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}